{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_train/search/zengziyang/miniconda3/envs/r1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/data_train/search/zengziyang/miniconda3/envs/r1/lib/python3.10/site-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data_train/search/zengziyang/miniconda3/envs/r1/lib/python3.10/site-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# os.environ[\"HF_ENDPOINT\"] = \"https://hf-mirror.com\"\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional, List\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "class TextSpan(BaseModel):\n",
    "    s: int\n",
    "    e: int\n",
    "    text: Optional[str] = None\n",
    "    module_name: str\n",
    "\n",
    "\n",
    "RETRIEVE_Q_PROMPT = \"<|START_INSTRUCTION|>Answer the question<|END_INSTRUCTION|>\"\n",
    "RETRIEVE_P_PROMPT = \"<|START_INSTRUCTION|>Candidate document<|END_INSTRUCTION|>\"\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"/processing_data/search/zengziyang/models/infgrad/dewey_en_beta\",\n",
    "    trust_remote_code=True,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ").cuda().bfloat16()\n",
    "model.tokenizer = AutoTokenizer.from_pretrained(\"/processing_data/search/zengziyang/models/infgrad/dewey_en_beta\")\n",
    "max_seq_length = 32 * 1024\n",
    "\n",
    "q_list = [\"why the sky is blue\"]\n",
    "p_list = [\n",
    "    \"\"\"\n",
    "    I’ve been trying to understand why the sky changes colors, and I think I understand most of it, but something in the online explanations doesn’t make it clear for me:\n",
    "\n",
    "I’ve read:\n",
    "\n",
    "sky is blue because blue light gets scattered the most during the day.\n",
    "\n",
    "in the evening it turns red because now even more of the blue light gets scattered\n",
    "\n",
    "So a few questions:\n",
    "\n",
    "The scattering of light during the day: does it mean that blue light gets reflected off air particles and reaches our eyes, while the rest of the frequencies pass through and reach the ground?\n",
    "\n",
    "Surely some of the other frequencies also get scattered during the day, just in much smaller amounts?\n",
    "\n",
    "So during the evening blue light gets scattered even more, to the point where even less of it reaches the eyes?\n",
    "\n",
    "And so it gets red because now we can see the lower frequencies being scattered without blue overshadowing them?\n",
    "\n",
    "Trying to word it myself: during the day only the highest frequencies get filtered, but during the evening also lower frequencies get filtered, because now the “light strainer” (air) is just catching more of it?\n",
    "\n",
    "It gets darker in the evening without a good ability to see colors because there’s is no blue and so on light to reflect off of objects?\n",
    "\n",
    "Is it ok to speak about light as a frequency? Or it’s only correct to say “wave length”?\n",
    "\n",
    "Blue light is scattered in all directions by the tiny molecules of air in Earth's atmosphere. Blue is scattered more than other colors because it travels as shorter, smaller waves. \n",
    "This is why we see a blue sky most of the time. Closer to the horizon, the sky fades to a lighter blue or white.\n",
    "    \"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoding text...: 100%|██████████| 1/1 [00:00<00:00, 40.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# query should be a single vector, so we set chunk_size as -1 to avoid chunk.\n",
    "# If chunk size is -1, the model will return an array with shape of (2,2048) consisting of cls_vector and mean_vector(mean of all token embeddings).\n",
    "query_vectors = model.encode(\n",
    "    sentences=q_list,\n",
    "    use_cuda=True,\n",
    "    show_progress_bar=True,\n",
    "    chunk_size=-1,\n",
    "    chunk_overlap=32,\n",
    "    convert_to_tensor=False,\n",
    "    max_seq_length=max_seq_length,\n",
    "    batch_size=8,\n",
    "    normalize_embeddings=True,\n",
    "    prompt=RETRIEVE_Q_PROMPT,\n",
    "    fast_chunk=False\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vectors = query_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2048)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "encoding text...: 100%|██████████| 1/1 [00:00<00:00, 22.33it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# spans_list contail each chunk's span, you can use span to get text\n",
    "spans_list: List[List[TextSpan]]\n",
    "passage_vectors_list: List[np.ndarray]\n",
    "passage_vectors_list, spans_list = model.encode(\n",
    "    sentences=p_list,\n",
    "    use_cuda=True,\n",
    "    show_progress_bar=True,\n",
    "    chunk_size=64,\n",
    "    chunk_overlap=8,\n",
    "    convert_to_tensor=False,\n",
    "    max_seq_length=max_seq_length,\n",
    "    batch_size=8,\n",
    "    normalize_embeddings=True,\n",
    "    prompt=RETRIEVE_P_PROMPT,\n",
    "    fast_chunk=True,  # if fast_chunk is true, directly chunk on input ids, else using RecursiveCharacterTextSplitter\n",
    ")\n",
    "\n",
    "# spans_list stores each passage's spans, passage_vectors_list stores each passage's vectors so len(spans_list) == len(p_list) and len(spans_list) == len(passage_vectors_list)\n",
    "# for a passage's spans and vectors, each span corresponds to a vector (1*2048). So, len(spans_list[idx]) ==  len(passage_vectors_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2048)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_vectors_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_vectors shape: (2048,)\n",
      "passage_vectors_list shape: (8, 2048)\n",
      "0.73425025\n"
     ]
    }
   ],
   "source": [
    "print(f\"query_vectors shape: {query_vectors[1].shape}\")\n",
    "print(f\"passage_vectors_list shape: {passage_vectors_list[0].shape}\")\n",
    "print((query_vectors[1] @ passage_vectors_list[0].T).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output 0.7331543\n",
    "# get each chunk's content\n",
    "for spans, passage in zip(spans_list, p_list):\n",
    "    text_ids = model.tokenizer.encode(RETRIEVE_P_PROMPT + passage)\n",
    "    for span in spans:\n",
    "        s, e = span.s, span.e\n",
    "        chunk_text = model.tokenizer.decode(\n",
    "            text_ids[s:e],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True\n",
    "        ).strip()\n",
    "        # print(chunk_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "r1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
