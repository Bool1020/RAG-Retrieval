# Model
model_name_or_path: "bge-reranker-m3-base"
model_type: "bert_encoder"
num_labels: 1
query_format: "{}"
document_format: "{}"


## Pointwise Dataset
train_dataset: "../../../example_data/pointwise_reranker_train_data.jsonl"
max_label: 2
min_label: 0
max_len: 512
shuffle_rate: 0.0
train_label_key: "label"
val_dataset: "../../../example_data/pointwise_reranker_eval_data.jsonl"
val_label_key: "label"

## Grouped Dataset
# train_dataset: "/data_train/search/zengziyang/projects/RAG-Retrieval/example_data/grouped_reranker_eval_0221_q199_p1130_n975.jsonl"
# train_dataset_type: "grouped"
# train_label_key: "gpt4o_listwise"
# train_group_size: 10
# shuffle_rate: 0.0
# max_len: 128
# val_dataset: "/data_train/search/zengziyang/projects/RAG-Retrieval/example_data/grouped_reranker_eval_0221_q199_p1130_n975.jsonl"
# val_dataset_type: "grouped"
# val_label_key: "gpt4o_listwise"


# Training
output_dir: "./output/bert"

## Model Saving
save_on_epoch_end: 1
num_max_checkpoints: 3

## Hyperparameters
loss_type: "pointwise_bce"  # "pointwise_bce" or "pointwise_mse" or "pairwise_ranknet" or "listwise_ce"
epochs: 2
lr: 5e-5
batch_size: 96
seed: 42
warmup_proportion: 0.1
stable_proportion: 0.0
gradient_accumulation_steps: 2
mixed_precision: fp16 

## Logging
log_interval: 10
log_with: "wandb" # "wandb" or "tensorboard"



